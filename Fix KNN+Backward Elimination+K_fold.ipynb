{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e934c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import datasets\n",
    "import statistics as st\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import *\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d76812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('fetal_health2.csv')\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81746e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline_Value = (df[\"baseline_value\"] - df[\"baseline_value\"].min())/ (df[\"baseline_value\"].max() - df[\"baseline_value\"].min())\n",
    "Accelerations = (df[\"accelerations\"] - df[\"accelerations\"].min()) / (df[\"accelerations\"].max() - df[\"accelerations\"].min())\n",
    "Fetal_Movement = (df[\"fetal_movement\"] - df[\"fetal_movement\"].min()) / (df[\"fetal_movement\"].max() - df[\"fetal_movement\"].min())\n",
    "Uterine_Contractions = (df[\"uterine_contractions\"] - df[\"uterine_contractions\"].min()) / (df[\"uterine_contractions\"].max() - df[\"uterine_contractions\"].min())\n",
    "Light_Decelerations = (df[\"light_decelerations\"] - df[\"light_decelerations\"].min()) / (df[\"light_decelerations\"].max() - df[\"light_decelerations\"].min())\n",
    "Severe_Decelerations = (df[\"severe_decelerations\"] - df[\"severe_decelerations\"].min()) / (df[\"severe_decelerations\"].max() - df[\"severe_decelerations\"].min())\n",
    "Prolongued_Decelerations = (df[\"prolongued_decelerations\"] - df[\"prolongued_decelerations\"].min()) / (df[\"prolongued_decelerations\"].max() - df[\"prolongued_decelerations\"].min())\n",
    "Abnormal_Shortterm_Variability = (df[\"abnormal_short_term_variability\"] - df[\"abnormal_short_term_variability\"].min()) / (df[\"abnormal_short_term_variability\"].max() - df[\"abnormal_short_term_variability\"].min())\n",
    "Meanvalue_of_Shortterm_Variability = (df[\"mean_value_of_short_term_variability\"] - df[\"mean_value_of_short_term_variability\"].min()) / (df[\"mean_value_of_short_term_variability\"].max() - df[\"mean_value_of_short_term_variability\"].min())\n",
    "Percentage_of_Timewith_Abnormal_Longterm_Variability = (df[\"percentage_of_time_with_abnormal_long_term_variability\"] - df[\"percentage_of_time_with_abnormal_long_term_variability\"].min()) / (df[\"percentage_of_time_with_abnormal_long_term_variability\"].max() - df[\"percentage_of_time_with_abnormal_long_term_variability\"].min())\n",
    "Mean_Value_of_Longterm_Variability = (df[\"mean_value_of_long_term_variability\"] - df[\"mean_value_of_long_term_variability\"].min()) / (df[\"mean_value_of_long_term_variability\"].max() - df[\"mean_value_of_long_term_variability\"].min())\n",
    "Histogram_Width = (df[\"histogram_width\"] - df[\"histogram_width\"].min()) / (df[\"histogram_width\"].max() - df[\"histogram_width\"].min())\n",
    "Histogram_Min = (df[\"histogram_min\"] - df[\"histogram_min\"].min()) / (df[\"histogram_min\"].max() - df[\"histogram_min\"].min())\n",
    "Histogram_Max = (df[\"histogram_max\"] - df[\"histogram_max\"].min()) / (df[\"histogram_max\"].max() - df[\"histogram_max\"].min())\n",
    "Histogram_Number_of_Peaks = (df[\"histogram_number_of_peaks\"] - df[\"histogram_number_of_peaks\"].min()) / (df[\"histogram_number_of_peaks\"].max() - df[\"histogram_number_of_peaks\"].min())\n",
    "Histogram_Number_of_Zeroes = (df[\"histogram_number_of_zeroes\"] - df[\"histogram_number_of_zeroes\"].min()) / (df[\"histogram_number_of_zeroes\"].max() - df[\"histogram_number_of_zeroes\"].min())\n",
    "Histogram_Mode = (df[\"histogram_mode\"] - df[\"histogram_mode\"].min()) / (df[\"histogram_mode\"].max() - df[\"histogram_mode\"].min())\n",
    "Histogram_Mean = (df[\"histogram_mean\"] - df[\"histogram_mean\"].min()) / (df[\"histogram_mean\"].max() - df[\"histogram_mean\"].min())\n",
    "Histogram_Median = (df[\"histogram_median\"] - df[\"histogram_median\"].min()) / (df[\"histogram_median\"].max() - df[\"histogram_median\"].min())\n",
    "Histogram_Variance = (df[\"histogram_variance\"] - df[\"histogram_variance\"].min()) / (df[\"histogram_variance\"].max() - df[\"histogram_variance\"].min())\n",
    "Histogram_Tendency = (df[\"histogram_tendency\"] - df[\"histogram_tendency\"].min()) / (df[\"histogram_tendency\"].max() - df[\"histogram_tendency\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da57b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "MinMax = []\n",
    "MinMax.append(Baseline_Value)\n",
    "MinMax.append(Accelerations)\n",
    "MinMax.append(Fetal_Movement)\n",
    "MinMax.append(Uterine_Contractions)\n",
    "MinMax.append(Light_Decelerations)\n",
    "MinMax.append(Severe_Decelerations)\n",
    "MinMax.append(Prolongued_Decelerations)\n",
    "MinMax.append(Abnormal_Shortterm_Variability)\n",
    "MinMax.append(Meanvalue_of_Shortterm_Variability)\n",
    "MinMax.append(Percentage_of_Timewith_Abnormal_Longterm_Variability)\n",
    "MinMax.append(Mean_Value_of_Longterm_Variability)\n",
    "MinMax.append(Histogram_Width)\n",
    "MinMax.append(Histogram_Min)\n",
    "MinMax.append(Histogram_Max)\n",
    "MinMax.append(Histogram_Number_of_Peaks)\n",
    "MinMax.append(Histogram_Number_of_Zeroes)\n",
    "MinMax.append(Histogram_Mode)\n",
    "MinMax.append(Histogram_Mean)\n",
    "MinMax.append(Histogram_Median)\n",
    "MinMax.append(Histogram_Variance)\n",
    "MinMax.append(Histogram_Tendency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5a1232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>...</th>\n",
       "      <th>histogram_width</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344633</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.271375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361582</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.614679</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      baseline_value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0           0.259259       0.000000        0.000000              0.000000   \n",
       "1           0.481481       0.315789        0.000000              0.400000   \n",
       "2           0.500000       0.157895        0.000000              0.533333   \n",
       "3           0.518519       0.157895        0.000000              0.533333   \n",
       "4           0.481481       0.368421        0.000000              0.533333   \n",
       "...              ...            ...             ...                   ...   \n",
       "2121        0.629630       0.000000        0.000000              0.466667   \n",
       "2122        0.629630       0.052632        0.000000              0.466667   \n",
       "2123        0.629630       0.052632        0.000000              0.466667   \n",
       "2124        0.629630       0.052632        0.000000              0.400000   \n",
       "2125        0.666667       0.105263        0.004158              0.533333   \n",
       "\n",
       "      light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                     0.0                   0.0                       0.0   \n",
       "1                     0.2                   0.0                       0.0   \n",
       "2                     0.2                   0.0                       0.0   \n",
       "3                     0.2                   0.0                       0.0   \n",
       "4                     0.0                   0.0                       0.0   \n",
       "...                   ...                   ...                       ...   \n",
       "2121                  0.0                   0.0                       0.0   \n",
       "2122                  0.0                   0.0                       0.0   \n",
       "2123                  0.0                   0.0                       0.0   \n",
       "2124                  0.0                   0.0                       0.0   \n",
       "2125                  0.0                   0.0                       0.0   \n",
       "\n",
       "      abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                            0.813333                              0.044118   \n",
       "1                            0.066667                              0.279412   \n",
       "2                            0.053333                              0.279412   \n",
       "3                            0.053333                              0.323529   \n",
       "4                            0.053333                              0.323529   \n",
       "...                               ...                                   ...   \n",
       "2121                         0.893333                              0.000000   \n",
       "2122                         0.880000                              0.029412   \n",
       "2123                         0.893333                              0.029412   \n",
       "2124                         0.880000                              0.029412   \n",
       "2125                         0.826667                              0.029412   \n",
       "\n",
       "      percentage_of_time_with_abnormal_long_term_variability  ...  \\\n",
       "0                                              0.472527       ...   \n",
       "1                                              0.000000       ...   \n",
       "2                                              0.000000       ...   \n",
       "3                                              0.000000       ...   \n",
       "4                                              0.000000       ...   \n",
       "...                                                 ...       ...   \n",
       "2121                                           0.274725       ...   \n",
       "2122                                           0.241758       ...   \n",
       "2123                                           0.219780       ...   \n",
       "2124                                           0.296703       ...   \n",
       "2125                                           0.395604       ...   \n",
       "\n",
       "      histogram_width  histogram_min  histogram_max  \\\n",
       "0            0.344633       0.110092       0.034483   \n",
       "1            0.717514       0.165138       0.655172   \n",
       "2            0.717514       0.165138       0.655172   \n",
       "3            0.644068       0.027523       0.413793   \n",
       "4            0.644068       0.027523       0.413793   \n",
       "...               ...            ...            ...   \n",
       "2121         0.209040       0.798165       0.474138   \n",
       "2122         0.355932       0.486239       0.405172   \n",
       "2123         0.361582       0.486239       0.413793   \n",
       "2124         0.355932       0.486239       0.405172   \n",
       "2125         0.220339       0.614679       0.318966   \n",
       "\n",
       "      histogram_number_of_peaks  histogram_number_of_zeroes  histogram_mode  \\\n",
       "0                      0.111111                         0.0        0.472441   \n",
       "1                      0.333333                         0.1        0.637795   \n",
       "2                      0.277778                         0.1        0.637795   \n",
       "3                      0.611111                         0.0        0.606299   \n",
       "4                      0.500000                         0.0        0.606299   \n",
       "...                         ...                         ...             ...   \n",
       "2121                   0.222222                         0.0        0.732283   \n",
       "2122                   0.333333                         0.0        0.724409   \n",
       "2123                   0.277778                         0.0        0.732283   \n",
       "2124                   0.333333                         0.0        0.724409   \n",
       "2125                   0.111111                         0.1        0.669291   \n",
       "\n",
       "      histogram_mean  histogram_median  histogram_variance  histogram_tendency  \n",
       "0           0.587156          0.403670            0.271375                 1.0  \n",
       "1           0.577982          0.577982            0.044610                 0.5  \n",
       "2           0.568807          0.559633            0.048327                 0.5  \n",
       "3           0.559633          0.550459            0.048327                 1.0  \n",
       "4           0.577982          0.559633            0.040892                 1.0  \n",
       "...              ...               ...                 ...                 ...  \n",
       "2121        0.706422          0.688073            0.007435                 0.5  \n",
       "2122        0.688073          0.678899            0.011152                 1.0  \n",
       "2123        0.688073          0.688073            0.014870                 1.0  \n",
       "2124        0.678899          0.678899            0.014870                 1.0  \n",
       "2125        0.642202          0.623853            0.003717                 0.5  \n",
       "\n",
       "[2126 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalisasi = pd.DataFrame(MinMax)\n",
    "normalisasi.to_numpy()\n",
    "dataset = normalisasi.T\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c524855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_EUCLIDEAN:\n",
    "    def __init__(self, k):\n",
    "        self.K=k\n",
    "        \n",
    "    def train(self, x,y):\n",
    "        self.X_train = x\n",
    "        self.y_train = y\n",
    "        \n",
    "    def jarak(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1-x2)**2))\n",
    "    \n",
    "    def _prediksi(self, x):\n",
    "        #hitung jarak kesemua data dtraning\n",
    "        jarak_titik = [self.jarak(x,X_train) for X_train in self.X_train]\n",
    "        #urutkan berdasarkan jarak terdekat, ambil sejumlah K\n",
    "        k_terbaik = np.argsort(jarak_titik)[:self.K]\n",
    "        #ambil label k_terbaik\n",
    "        label_k_terbaik = [self.y_train[i] for i in k_terbaik]\n",
    "        #voting yang paling banyak\n",
    "        hasil_voting = Counter(label_k_terbaik).most_common(1)\n",
    "        return hasil_voting[0][0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_prediksi = [self._prediksi(x) for x in X]\n",
    "        return np.array(y_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff50a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_MANHATTAN:\n",
    "    def __init__(self, k):\n",
    "        self.K=k\n",
    "        \n",
    "    def train(self, x,y):\n",
    "        self.X_train = x\n",
    "        self.y_train = y\n",
    "        \n",
    "    def jarak(self, x1, x2):\n",
    "        return np.sum(abs(x1-x2))\n",
    "    \n",
    "    def _prediksi(self, x):\n",
    "        #hitung jarak kesemua data dtraning\n",
    "        jarak_titik = [self.jarak(x,X_train) for X_train in self.X_train]\n",
    "        #urutkan berdasarkan jarak terdekat, ambil sejumlah K\n",
    "        k_terbaik = np.argsort(jarak_titik)[:self.K]\n",
    "        #ambil label k_terbaik\n",
    "        label_k_terbaik = [self.y_train[i] for i in k_terbaik]\n",
    "        #voting yang paling banyak\n",
    "        hasil_voting = Counter(label_k_terbaik).most_common(1)\n",
    "        return hasil_voting[0][0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_prediksi = [self._prediksi(x) for x in X]\n",
    "        return np.array(y_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0617410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jarak_minkowski(x1, x2, p): \n",
    "    equ_part1 = np.sum(np.power(np.abs(x1 - x2), p))\n",
    "    distance = np.power(equ_part1, 1 / p)\n",
    "    return np.round(distance, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa622f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_MINKOWSKI:\n",
    "    def __init__(self, k, p):\n",
    "        self.K=k\n",
    "        self.P=p\n",
    "        \n",
    "    def train(self, x,y):\n",
    "        self.X_train = x\n",
    "        self.y_train = y\n",
    "    \n",
    "    def _prediksi(self, x1):\n",
    "        #hitung jarak kesemua data dtraning\n",
    "        jarak_titik = [jarak_minkowski(x1, x2, self.P) for x2 in self.X_train]\n",
    "        #urutkan berdasarkan jarak terdekat, ambil sejumlah K\n",
    "        k_terbaik = np.argsort(jarak_titik)[:self.K]\n",
    "        #ambil label k_terbaik\n",
    "        label_k_terbaik = [self.y_train[i] for i in k_terbaik]\n",
    "        #voting yang paling banyak\n",
    "        hasil_voting = Counter(label_k_terbaik).most_common(1)\n",
    "        return hasil_voting[0][0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_prediksi = [self._prediksi(x) for x in X]\n",
    "        return np.array(y_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "663806ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=0, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6dfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "sl = 0.05\n",
    "X = np.append(arr = np.ones((2126,0)).astype(int), values = dataset, axis = 1) \n",
    "X_opt = X[:]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "def backwardElimination(X, sl):\n",
    "    numVars = len(X[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, X).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    X = np.delete(X, j, 1)\n",
    "                    regressor_OLS.summary()\n",
    "    return X\n",
    "\n",
    "SL = 0.05\n",
    "X_train_opt = X[:]\n",
    "X_Modeled = backwardElimination(X_train_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faca9633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344633</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.271375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361582</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.614679</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3    4    5    6         7   \\\n",
       "0     0.259259  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.813333   \n",
       "1     0.481481  0.315789  0.000000  0.400000  0.2  0.0  0.0  0.066667   \n",
       "2     0.500000  0.157895  0.000000  0.533333  0.2  0.0  0.0  0.053333   \n",
       "3     0.518519  0.157895  0.000000  0.533333  0.2  0.0  0.0  0.053333   \n",
       "4     0.481481  0.368421  0.000000  0.533333  0.0  0.0  0.0  0.053333   \n",
       "...        ...       ...       ...       ...  ...  ...  ...       ...   \n",
       "2121  0.629630  0.000000  0.000000  0.466667  0.0  0.0  0.0  0.893333   \n",
       "2122  0.629630  0.052632  0.000000  0.466667  0.0  0.0  0.0  0.880000   \n",
       "2123  0.629630  0.052632  0.000000  0.466667  0.0  0.0  0.0  0.893333   \n",
       "2124  0.629630  0.052632  0.000000  0.400000  0.0  0.0  0.0  0.880000   \n",
       "2125  0.666667  0.105263  0.004158  0.533333  0.0  0.0  0.0  0.826667   \n",
       "\n",
       "            8         9   ...        11        12        13        14   15  \\\n",
       "0     0.044118  0.472527  ...  0.344633  0.110092  0.034483  0.111111  0.0   \n",
       "1     0.279412  0.000000  ...  0.717514  0.165138  0.655172  0.333333  0.1   \n",
       "2     0.279412  0.000000  ...  0.717514  0.165138  0.655172  0.277778  0.1   \n",
       "3     0.323529  0.000000  ...  0.644068  0.027523  0.413793  0.611111  0.0   \n",
       "4     0.323529  0.000000  ...  0.644068  0.027523  0.413793  0.500000  0.0   \n",
       "...        ...       ...  ...       ...       ...       ...       ...  ...   \n",
       "2121  0.000000  0.274725  ...  0.209040  0.798165  0.474138  0.222222  0.0   \n",
       "2122  0.029412  0.241758  ...  0.355932  0.486239  0.405172  0.333333  0.0   \n",
       "2123  0.029412  0.219780  ...  0.361582  0.486239  0.413793  0.277778  0.0   \n",
       "2124  0.029412  0.296703  ...  0.355932  0.486239  0.405172  0.333333  0.0   \n",
       "2125  0.029412  0.395604  ...  0.220339  0.614679  0.318966  0.111111  0.1   \n",
       "\n",
       "            16        17        18        19   20  \n",
       "0     0.472441  0.587156  0.403670  0.271375  1.0  \n",
       "1     0.637795  0.577982  0.577982  0.044610  0.5  \n",
       "2     0.637795  0.568807  0.559633  0.048327  0.5  \n",
       "3     0.606299  0.559633  0.550459  0.048327  1.0  \n",
       "4     0.606299  0.577982  0.559633  0.040892  1.0  \n",
       "...        ...       ...       ...       ...  ...  \n",
       "2121  0.732283  0.706422  0.688073  0.007435  0.5  \n",
       "2122  0.724409  0.688073  0.678899  0.011152  1.0  \n",
       "2123  0.732283  0.688073  0.688073  0.014870  1.0  \n",
       "2124  0.724409  0.678899  0.678899  0.014870  1.0  \n",
       "2125  0.669291  0.642202  0.623853  0.003717  0.5  \n",
       "\n",
       "[2126 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f33ce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.344633</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.472441</td>\n",
       "      <td>0.403670</td>\n",
       "      <td>0.271375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.165138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453649</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392505</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.142012</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.140039</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.361582</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.138067</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.098619</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.614679</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1    2    3         4         5         6         7   \\\n",
       "0     0.259259  0.000000  0.0  0.0  0.813333  0.472527  0.047337  0.344633   \n",
       "1     0.481481  0.400000  0.0  0.0  0.066667  0.000000  0.205128  0.717514   \n",
       "2     0.500000  0.533333  0.0  0.0  0.053333  0.000000  0.264300  0.717514   \n",
       "3     0.518519  0.533333  0.0  0.0  0.053333  0.000000  0.453649  0.644068   \n",
       "4     0.481481  0.533333  0.0  0.0  0.053333  0.000000  0.392505  0.644068   \n",
       "...        ...       ...  ...  ...       ...       ...       ...       ...   \n",
       "2121  0.629630  0.466667  0.0  0.0  0.893333  0.274725  0.142012  0.209040   \n",
       "2122  0.629630  0.466667  0.0  0.0  0.880000  0.241758  0.140039  0.355932   \n",
       "2123  0.629630  0.466667  0.0  0.0  0.893333  0.219780  0.120316  0.361582   \n",
       "2124  0.629630  0.400000  0.0  0.0  0.880000  0.296703  0.138067  0.355932   \n",
       "2125  0.666667  0.533333  0.0  0.0  0.826667  0.395604  0.098619  0.220339   \n",
       "\n",
       "            8         9         10        11        12   13  \n",
       "0     0.110092  0.034483  0.472441  0.403670  0.271375  1.0  \n",
       "1     0.165138  0.655172  0.637795  0.577982  0.044610  0.5  \n",
       "2     0.165138  0.655172  0.637795  0.559633  0.048327  0.5  \n",
       "3     0.027523  0.413793  0.606299  0.550459  0.048327  1.0  \n",
       "4     0.027523  0.413793  0.606299  0.559633  0.040892  1.0  \n",
       "...        ...       ...       ...       ...       ...  ...  \n",
       "2121  0.798165  0.474138  0.732283  0.688073  0.007435  0.5  \n",
       "2122  0.486239  0.405172  0.724409  0.678899  0.011152  1.0  \n",
       "2123  0.486239  0.413793  0.732283  0.688073  0.014870  1.0  \n",
       "2124  0.486239  0.405172  0.724409  0.678899  0.014870  1.0  \n",
       "2125  0.614679  0.318966  0.669291  0.623853  0.003717  0.5  \n",
       "\n",
       "[2126 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_Modeled)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1789eb65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENGGUNAKAN EUCLIDEAN DISTANCE\n",
      "K = 3\n",
      "[[313  11   2]\n",
      " [ 19  36   3]\n",
      " [  5   5  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.96      0.94       326\n",
      "           2       0.69      0.62      0.65        58\n",
      "           3       0.86      0.76      0.81        42\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.83      0.78      0.80       426\n",
      "weighted avg       0.89      0.89      0.89       426\n",
      "\n",
      "[[327   3   0]\n",
      " [ 23  41   4]\n",
      " [  1   3  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       330\n",
      "           2       0.87      0.60      0.71        68\n",
      "           3       0.85      0.85      0.85        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.89      0.82      0.84       425\n",
      "weighted avg       0.92      0.92      0.91       425\n",
      "\n",
      "[[325   8   0]\n",
      " [ 18  34   4]\n",
      " [  5   4  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.95       333\n",
      "           2       0.74      0.61      0.67        56\n",
      "           3       0.87      0.75      0.81        36\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.85      0.78      0.81       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "[[323  12   0]\n",
      " [ 21  32   3]\n",
      " [  8   3  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94       335\n",
      "           2       0.68      0.57      0.62        56\n",
      "           3       0.88      0.68      0.77        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.83      0.74      0.78       425\n",
      "weighted avg       0.88      0.89      0.88       425\n",
      "\n",
      "[[323   6   2]\n",
      " [ 18  37   2]\n",
      " [  3   8  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       331\n",
      "           2       0.73      0.65      0.69        57\n",
      "           3       0.87      0.70      0.78        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.84      0.78      0.81       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "akurasi :  0.9040497100248551\n",
      "akurasi 5-fold :  [0.8943661971830986, 0.92, 0.908235294117647, 0.8894117647058823, 0.908235294117647]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 5\n",
      "[[312  12   2]\n",
      " [ 25  32   1]\n",
      " [  5   6  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.96      0.93       326\n",
      "           2       0.64      0.55      0.59        58\n",
      "           3       0.91      0.74      0.82        42\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.82      0.75      0.78       426\n",
      "weighted avg       0.88      0.88      0.88       426\n",
      "\n",
      "[[328   2   0]\n",
      " [ 23  44   1]\n",
      " [  2   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       330\n",
      "           2       0.88      0.65      0.75        68\n",
      "           3       0.95      0.78      0.86        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.92      0.81      0.85       425\n",
      "weighted avg       0.92      0.92      0.92       425\n",
      "\n",
      "[[324   9   0]\n",
      " [ 19  37   0]\n",
      " [  6   6  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.97      0.95       333\n",
      "           2       0.71      0.66      0.69        56\n",
      "           3       1.00      0.67      0.80        36\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.88      0.77      0.81       425\n",
      "weighted avg       0.91      0.91      0.90       425\n",
      "\n",
      "[[323  12   0]\n",
      " [ 21  32   3]\n",
      " [ 10   1  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.96      0.94       335\n",
      "           2       0.71      0.57      0.63        56\n",
      "           3       0.88      0.68      0.77        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.84      0.74      0.78       425\n",
      "weighted avg       0.88      0.89      0.88       425\n",
      "\n",
      "[[325   5   1]\n",
      " [ 19  36   2]\n",
      " [  3   7  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       331\n",
      "           2       0.75      0.63      0.69        57\n",
      "           3       0.90      0.73      0.81        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.86      0.78      0.82       425\n",
      "weighted avg       0.91      0.91      0.91       425\n",
      "\n",
      "akurasi :  0.9026445733222866\n",
      "akurasi 5-fold :  [0.8802816901408451, 0.9247058823529412, 0.9058823529411765, 0.8894117647058823, 0.9129411764705883]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 7\n",
      "[[316  10   0]\n",
      " [ 27  30   1]\n",
      " [  7   6  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.97      0.93       326\n",
      "           2       0.65      0.52      0.58        58\n",
      "           3       0.97      0.69      0.81        42\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.84      0.73      0.77       426\n",
      "weighted avg       0.88      0.88      0.87       426\n",
      "\n",
      "[[329   1   0]\n",
      " [ 25  41   2]\n",
      " [  2   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      1.00      0.96       330\n",
      "           2       0.89      0.60      0.72        68\n",
      "           3       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.91      0.79      0.84       425\n",
      "weighted avg       0.92      0.92      0.91       425\n",
      "\n",
      "[[327   6   0]\n",
      " [ 24  32   0]\n",
      " [  9   7  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.98      0.94       333\n",
      "           2       0.71      0.57      0.63        56\n",
      "           3       1.00      0.56      0.71        36\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.87      0.70      0.76       425\n",
      "weighted avg       0.89      0.89      0.88       425\n",
      "\n",
      "[[324  11   0]\n",
      " [ 20  35   1]\n",
      " [  9   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       335\n",
      "           2       0.70      0.62      0.66        56\n",
      "           3       0.95      0.62      0.75        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.86      0.74      0.78       425\n",
      "weighted avg       0.89      0.89      0.89       425\n",
      "\n",
      "[[326   5   0]\n",
      " [ 20  36   1]\n",
      " [  3  10  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.96       331\n",
      "           2       0.71      0.63      0.67        57\n",
      "           3       0.96      0.65      0.77        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.87      0.76      0.80       425\n",
      "weighted avg       0.91      0.91      0.90       425\n",
      "\n",
      "akurasi :  0.8988798674399338\n",
      "akurasi 5-fold :  [0.8802816901408451, 0.92, 0.8917647058823529, 0.8941176470588236, 0.908235294117647]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 9\n",
      "[[315  10   1]\n",
      " [ 28  29   1]\n",
      " [  6   6  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.97      0.93       326\n",
      "           2       0.64      0.50      0.56        58\n",
      "           3       0.94      0.71      0.81        42\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.83      0.73      0.77       426\n",
      "weighted avg       0.87      0.88      0.87       426\n",
      "\n",
      "[[329   1   0]\n",
      " [ 25  42   1]\n",
      " [  3   4  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      1.00      0.96       330\n",
      "           2       0.89      0.62      0.73        68\n",
      "           3       0.95      0.74      0.83        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.92      0.79      0.84       425\n",
      "weighted avg       0.92      0.92      0.91       425\n",
      "\n",
      "[[326   7   0]\n",
      " [ 26  27   3]\n",
      " [  9   6  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.98      0.94       333\n",
      "           2       0.68      0.48      0.56        56\n",
      "           3       0.88      0.58      0.70        36\n",
      "\n",
      "    accuracy                           0.88       425\n",
      "   macro avg       0.82      0.68      0.73       425\n",
      "weighted avg       0.87      0.88      0.87       425\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325  10   0]\n",
      " [ 20  34   2]\n",
      " [ 11   3  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.97      0.94       335\n",
      "           2       0.72      0.61      0.66        56\n",
      "           3       0.91      0.59      0.71        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.85      0.72      0.77       425\n",
      "weighted avg       0.89      0.89      0.89       425\n",
      "\n",
      "[[326   4   1]\n",
      " [ 20  35   2]\n",
      " [  3  10  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.96       331\n",
      "           2       0.71      0.61      0.66        57\n",
      "           3       0.89      0.65      0.75        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.85      0.75      0.79       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "akurasi :  0.8951162662247997\n",
      "akurasi 5-fold :  [0.8779342723004695, 0.92, 0.88, 0.8917647058823529, 0.9058823529411765]\n",
      "Hasil Klasifikasi :  1\n",
      "[0.9040497100248551, 0.9026445733222866, 0.8988798674399338, 0.8951162662247997]\n",
      "\n",
      "MENGGUNAKAN MANHATTAN DISTANCE\n",
      "K = 3\n",
      "[[312  12   2]\n",
      " [ 18  37   3]\n",
      " [  4   6  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.96      0.95       326\n",
      "           2       0.67      0.64      0.65        58\n",
      "           3       0.86      0.76      0.81        42\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.82      0.79      0.80       426\n",
      "weighted avg       0.89      0.89      0.89       426\n",
      "\n",
      "[[327   3   0]\n",
      " [ 19  47   2]\n",
      " [  2   3  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.99      0.96       330\n",
      "           2       0.89      0.69      0.78        68\n",
      "           3       0.92      0.81      0.86        27\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.91      0.83      0.87       425\n",
      "weighted avg       0.93      0.93      0.93       425\n",
      "\n",
      "[[327   5   1]\n",
      " [ 17  35   4]\n",
      " [  3   4  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       333\n",
      "           2       0.80      0.62      0.70        56\n",
      "           3       0.85      0.81      0.83        36\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.86      0.80      0.83       425\n",
      "weighted avg       0.92      0.92      0.92       425\n",
      "\n",
      "[[325  10   0]\n",
      " [ 18  36   2]\n",
      " [  7   4  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.97      0.95       335\n",
      "           2       0.72      0.64      0.68        56\n",
      "           3       0.92      0.68      0.78        34\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.86      0.76      0.80       425\n",
      "weighted avg       0.90      0.90      0.90       425\n",
      "\n",
      "[[325   5   1]\n",
      " [ 16  38   3]\n",
      " [  3   8  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       331\n",
      "           2       0.75      0.67      0.70        57\n",
      "           3       0.87      0.70      0.78        37\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.85      0.78      0.81       425\n",
      "weighted avg       0.91      0.92      0.91       425\n",
      "\n",
      "akurasi :  0.9129908864954432\n",
      "akurasi 5-fold :  [0.8943661971830986, 0.9317647058823529, 0.92, 0.9035294117647059, 0.9152941176470588]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 5\n",
      "[[315   9   2]\n",
      " [ 20  36   2]\n",
      " [  6   5  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       326\n",
      "           2       0.72      0.62      0.67        58\n",
      "           3       0.89      0.74      0.81        42\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.84      0.78      0.81       426\n",
      "weighted avg       0.89      0.90      0.89       426\n",
      "\n",
      "[[329   1   0]\n",
      " [ 23  43   2]\n",
      " [  2   6  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      1.00      0.96       330\n",
      "           2       0.86      0.63      0.73        68\n",
      "           3       0.90      0.70      0.79        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.90      0.78      0.83       425\n",
      "weighted avg       0.92      0.92      0.91       425\n",
      "\n",
      "[[324   8   1]\n",
      " [ 19  36   1]\n",
      " [  5   6  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.97      0.95       333\n",
      "           2       0.72      0.64      0.68        56\n",
      "           3       0.93      0.69      0.79        36\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.86      0.77      0.81       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "[[324  11   0]\n",
      " [ 20  34   2]\n",
      " [  9   2  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       335\n",
      "           2       0.72      0.61      0.66        56\n",
      "           3       0.92      0.68      0.78        34\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.85      0.75      0.79       425\n",
      "weighted avg       0.89      0.90      0.89       425\n",
      "\n",
      "[[324   5   2]\n",
      " [ 20  35   2]\n",
      " [  3   9  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.96       331\n",
      "           2       0.71      0.61      0.66        57\n",
      "           3       0.86      0.68      0.76        37\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.84      0.76      0.79       425\n",
      "weighted avg       0.90      0.90      0.90       425\n",
      "\n",
      "akurasi :  0.9045191935929301\n",
      "akurasi 5-fold :  [0.8967136150234741, 0.92, 0.9058823529411765, 0.8964705882352941, 0.9035294117647059]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 7\n",
      "[[314  10   2]\n",
      " [ 23  34   1]\n",
      " [  6   5  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94       326\n",
      "           2       0.69      0.59      0.64        58\n",
      "           3       0.91      0.74      0.82        42\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.84      0.76      0.80       426\n",
      "weighted avg       0.88      0.89      0.89       426\n",
      "\n",
      "[[329   1   0]\n",
      " [ 22  44   2]\n",
      " [  2   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      1.00      0.96       330\n",
      "           2       0.90      0.65      0.75        68\n",
      "           3       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.93       425\n",
      "   macro avg       0.91      0.81      0.85       425\n",
      "weighted avg       0.93      0.93      0.92       425\n",
      "\n",
      "[[327   5   1]\n",
      " [ 18  37   1]\n",
      " [  5   7  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.96       333\n",
      "           2       0.76      0.66      0.70        56\n",
      "           3       0.92      0.67      0.77        36\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.87      0.77      0.81       425\n",
      "weighted avg       0.91      0.91      0.91       425\n",
      "\n",
      "[[325  10   0]\n",
      " [ 20  35   1]\n",
      " [  9   3  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       335\n",
      "           2       0.73      0.62      0.67        56\n",
      "           3       0.96      0.65      0.77        34\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.87      0.75      0.80       425\n",
      "weighted avg       0.90      0.90      0.89       425\n",
      "\n",
      "[[326   5   0]\n",
      " [ 19  35   3]\n",
      " [  3   8  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       331\n",
      "           2       0.73      0.61      0.67        57\n",
      "           3       0.90      0.70      0.79        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.85      0.77      0.80       425\n",
      "weighted avg       0.91      0.91      0.91       425\n",
      "\n",
      "akurasi :  0.9078166252416459\n",
      "akurasi 5-fold :  [0.8896713615023474, 0.9270588235294117, 0.9129411764705883, 0.8988235294117647, 0.9105882352941177]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 9\n",
      "[[316  10   0]\n",
      " [ 25  33   0]\n",
      " [  7   5  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.97      0.94       326\n",
      "           2       0.69      0.57      0.62        58\n",
      "           3       1.00      0.71      0.83        42\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.87      0.75      0.80       426\n",
      "weighted avg       0.89      0.89      0.88       426\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[329   1   0]\n",
      " [ 26  41   1]\n",
      " [  3   4  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      1.00      0.96       330\n",
      "           2       0.89      0.60      0.72        68\n",
      "           3       0.95      0.74      0.83        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.92      0.78      0.84       425\n",
      "weighted avg       0.92      0.92      0.91       425\n",
      "\n",
      "[[328   4   1]\n",
      " [ 21  29   6]\n",
      " [  6   7  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.98      0.95       333\n",
      "           2       0.72      0.52      0.60        56\n",
      "           3       0.77      0.64      0.70        36\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.81      0.71      0.75       425\n",
      "weighted avg       0.88      0.89      0.89       425\n",
      "\n",
      "[[324  11   0]\n",
      " [ 21  33   2]\n",
      " [  9   3  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       335\n",
      "           2       0.70      0.59      0.64        56\n",
      "           3       0.92      0.65      0.76        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.84      0.73      0.78       425\n",
      "weighted avg       0.89      0.89      0.89       425\n",
      "\n",
      "[[329   2   0]\n",
      " [ 23  32   2]\n",
      " [  2   9  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       331\n",
      "           2       0.74      0.56      0.64        57\n",
      "           3       0.93      0.70      0.80        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.87      0.75      0.80       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "akurasi :  0.9007578017122342\n",
      "akurasi 5-fold :  [0.8896713615023474, 0.9176470588235294, 0.8941176470588236, 0.8917647058823529, 0.9105882352941177]\n",
      "Hasil Klasifikasi :  1\n",
      "[0.9129908864954432, 0.9045191935929301, 0.9078166252416459, 0.9007578017122342]\n",
      "\n",
      "MENGGUNAKAN MINKOWSKI DISTANCE\n",
      "K = 3\n",
      "[[313  11   2]\n",
      " [ 22  33   3]\n",
      " [  5   5  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94       326\n",
      "           2       0.67      0.57      0.62        58\n",
      "           3       0.86      0.76      0.81        42\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.82      0.76      0.79       426\n",
      "weighted avg       0.88      0.89      0.88       426\n",
      "\n",
      "[[326   4   0]\n",
      " [ 25  39   4]\n",
      " [  1   3  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       330\n",
      "           2       0.85      0.57      0.68        68\n",
      "           3       0.85      0.85      0.85        27\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.88      0.80      0.83       425\n",
      "weighted avg       0.91      0.91      0.91       425\n",
      "\n",
      "[[325   8   0]\n",
      " [ 17  34   5]\n",
      " [  5   4  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       333\n",
      "           2       0.74      0.61      0.67        56\n",
      "           3       0.84      0.75      0.79        36\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.84      0.78      0.81       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "[[323  12   0]\n",
      " [ 21  32   3]\n",
      " [  8   3  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94       335\n",
      "           2       0.68      0.57      0.62        56\n",
      "           3       0.88      0.68      0.77        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.83      0.74      0.78       425\n",
      "weighted avg       0.88      0.89      0.88       425\n",
      "\n",
      "[[324   4   3]\n",
      " [ 19  36   2]\n",
      " [  3   8  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       331\n",
      "           2       0.75      0.63      0.69        57\n",
      "           3       0.84      0.70      0.76        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.84      0.77      0.80       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "akurasi :  0.9012294946147474\n",
      "akurasi 5-fold :  [0.8873239436619719, 0.9129411764705883, 0.908235294117647, 0.8894117647058823, 0.908235294117647]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 5\n",
      "[[312  13   1]\n",
      " [ 26  30   2]\n",
      " [  6   5  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.96      0.93       326\n",
      "           2       0.62      0.52      0.57        58\n",
      "           3       0.91      0.74      0.82        42\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.81      0.74      0.77       426\n",
      "weighted avg       0.87      0.88      0.87       426\n",
      "\n",
      "[[328   2   0]\n",
      " [ 24  42   2]\n",
      " [  1   3  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       330\n",
      "           2       0.89      0.62      0.73        68\n",
      "           3       0.92      0.85      0.88        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.91      0.82      0.86       425\n",
      "weighted avg       0.92      0.92      0.92       425\n",
      "\n",
      "[[326   6   1]\n",
      " [ 21  34   1]\n",
      " [  8   5  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.98      0.95       333\n",
      "           2       0.76      0.61      0.67        56\n",
      "           3       0.92      0.64      0.75        36\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.86      0.74      0.79       425\n",
      "weighted avg       0.90      0.90      0.90       425\n",
      "\n",
      "[[324  11   0]\n",
      " [ 21  33   2]\n",
      " [  6   3  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       335\n",
      "           2       0.70      0.59      0.64        56\n",
      "           3       0.93      0.74      0.82        34\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.85      0.76      0.80       425\n",
      "weighted avg       0.89      0.90      0.89       425\n",
      "\n",
      "[[322   8   1]\n",
      " [ 19  36   2]\n",
      " [  3   7  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.97      0.95       331\n",
      "           2       0.71      0.63      0.67        57\n",
      "           3       0.90      0.73      0.81        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.85      0.78      0.81       425\n",
      "weighted avg       0.90      0.91      0.90       425\n",
      "\n",
      "akurasi :  0.9012350179508424\n",
      "akurasi 5-fold :  [0.8755868544600939, 0.9247058823529412, 0.9011764705882352, 0.8988235294117647, 0.9058823529411765]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 7\n",
      "[[312  14   0]\n",
      " [ 28  29   1]\n",
      " [  7   6  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.96      0.93       326\n",
      "           2       0.59      0.50      0.54        58\n",
      "           3       0.97      0.69      0.81        42\n",
      "\n",
      "    accuracy                           0.87       426\n",
      "   macro avg       0.82      0.72      0.76       426\n",
      "weighted avg       0.86      0.87      0.86       426\n",
      "\n",
      "[[328   2   0]\n",
      " [ 24  42   2]\n",
      " [  1   4  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       330\n",
      "           2       0.88      0.62      0.72        68\n",
      "           3       0.92      0.81      0.86        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.91      0.81      0.85       425\n",
      "weighted avg       0.92      0.92      0.92       425\n",
      "\n",
      "[[327   5   1]\n",
      " [ 27  29   0]\n",
      " [  9   7  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.98      0.94       333\n",
      "           2       0.71      0.52      0.60        56\n",
      "           3       0.95      0.56      0.70        36\n",
      "\n",
      "    accuracy                           0.88       425\n",
      "   macro avg       0.85      0.69      0.75       425\n",
      "weighted avg       0.88      0.88      0.87       425\n",
      "\n",
      "[[326   9   0]\n",
      " [ 20  34   2]\n",
      " [  9   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.97      0.94       335\n",
      "           2       0.72      0.61      0.66        56\n",
      "           3       0.91      0.62      0.74        34\n",
      "\n",
      "    accuracy                           0.90       425\n",
      "   macro avg       0.85      0.73      0.78       425\n",
      "weighted avg       0.89      0.90      0.89       425\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325   6   0]\n",
      " [ 20  36   1]\n",
      " [  3   8  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.96       331\n",
      "           2       0.72      0.63      0.67        57\n",
      "           3       0.96      0.70      0.81        37\n",
      "\n",
      "    accuracy                           0.91       425\n",
      "   macro avg       0.87      0.77      0.81       425\n",
      "weighted avg       0.91      0.91      0.91       425\n",
      "\n",
      "akurasi :  0.8965324495995581\n",
      "akurasi 5-fold :  [0.8685446009389671, 0.9223529411764706, 0.8847058823529412, 0.8964705882352941, 0.9105882352941177]\n",
      "Hasil Klasifikasi :  1\n",
      "K = 9\n",
      "[[317   8   1]\n",
      " [ 27  30   1]\n",
      " [  7   6  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.97      0.94       326\n",
      "           2       0.68      0.52      0.59        58\n",
      "           3       0.94      0.69      0.79        42\n",
      "\n",
      "    accuracy                           0.88       426\n",
      "   macro avg       0.84      0.73      0.77       426\n",
      "weighted avg       0.88      0.88      0.88       426\n",
      "\n",
      "[[327   3   0]\n",
      " [ 26  41   1]\n",
      " [  2   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.99      0.95       330\n",
      "           2       0.85      0.60      0.71        68\n",
      "           3       0.95      0.78      0.86        27\n",
      "\n",
      "    accuracy                           0.92       425\n",
      "   macro avg       0.91      0.79      0.84       425\n",
      "weighted avg       0.91      0.92      0.91       425\n",
      "\n",
      "[[327   5   1]\n",
      " [ 27  26   3]\n",
      " [ 10   5  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.98      0.94       333\n",
      "           2       0.72      0.46      0.57        56\n",
      "           3       0.84      0.58      0.69        36\n",
      "\n",
      "    accuracy                           0.88       425\n",
      "   macro avg       0.82      0.68      0.73       425\n",
      "weighted avg       0.87      0.88      0.87       425\n",
      "\n",
      "[[322  13   0]\n",
      " [ 20  35   1]\n",
      " [  9   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94       335\n",
      "           2       0.67      0.62      0.65        56\n",
      "           3       0.95      0.62      0.75        34\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.85      0.73      0.78       425\n",
      "weighted avg       0.89      0.89      0.89       425\n",
      "\n",
      "[[324   7   0]\n",
      " [ 23  32   2]\n",
      " [  3  11  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.98      0.95       331\n",
      "           2       0.64      0.56      0.60        57\n",
      "           3       0.92      0.62      0.74        37\n",
      "\n",
      "    accuracy                           0.89       425\n",
      "   macro avg       0.83      0.72      0.76       425\n",
      "weighted avg       0.89      0.89      0.89       425\n",
      "\n",
      "akurasi :  0.8918199392433029\n",
      "akurasi 5-fold :  [0.8826291079812206, 0.9152941176470588, 0.88, 0.8894117647058823, 0.8917647058823529]\n",
      "Hasil Klasifikasi :  1\n",
      "[0.9012294946147474, 0.9012350179508424, 0.8965324495995581, 0.8918199392433029]\n",
      "Runtime KNN with Euclidean Distance : 26.952946186065674\n",
      "Runtime KNN with Manhattan Distance : 19.384395360946655\n",
      "Runtime KNN with Minkowski Distance : 72.73159527778625\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "        accuracy= np.sum(y_true == y_pred)/len(y_true)\n",
    "        return accuracy\n",
    "print(\"MENGGUNAKAN EUCLIDEAN DISTANCE\")\n",
    "\n",
    "from collections import Counter\n",
    "import statistics as st\n",
    "hasil1 = []\n",
    "for i in range (3, 10, 2):\n",
    "    pred1 = []\n",
    "    print('K =', i) \n",
    "    start1 = time.time()\n",
    "    model = KNN_EUCLIDEAN(k=i)\n",
    "    for train_index, test_index in kf.split(X_Modeled):\n",
    "        X_train, X_test = X_Modeled[train_index], X_Modeled[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.train(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        end1 = time.time()\n",
    "        acc = accuracy(y_test, y_pred)\n",
    "        pred1.append(accuracy(y_test, y_pred))\n",
    "        \n",
    "        print(confusion_matrix(y_test, y_pred)) \n",
    "        print(classification_report(y_test, y_pred))\n",
    "         \n",
    "        \n",
    "    print(\"akurasi : \", np.mean(pred1))\n",
    "    hasil1.append(np.mean(pred1))\n",
    "    print(\"akurasi 5-fold : \", pred1)\n",
    "\n",
    "    #classification\n",
    "    data1 = []\n",
    "    for i in y_pred:\n",
    "        data1.append(int(i))\n",
    "        \n",
    "    modus = st.mode(data1)\n",
    "    print(\"Hasil Klasifikasi : \", modus)\n",
    "print(hasil1)\n",
    "\n",
    "print(\"\\nMENGGUNAKAN MANHATTAN DISTANCE\")\n",
    "hasil2 = []\n",
    "for i in range (3, 10, 2):\n",
    "    pred2 = []\n",
    "    print('K =', i) \n",
    "    start2 = time.time()\n",
    "    model = KNN_MANHATTAN(k=i)\n",
    "    for train_index, test_index in kf.split(X_Modeled):\n",
    "        X_train, X_test = X_Modeled[train_index], X_Modeled[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.train(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        end2 = time.time()\n",
    "        acc = accuracy(y_test, y_pred)\n",
    "        pred2.append(accuracy(y_test, y_pred))\n",
    "        \n",
    "        print(confusion_matrix(y_test, y_pred)) \n",
    "        print(classification_report(y_test, y_pred))\n",
    "         \n",
    "    print(\"akurasi : \", np.mean(pred2))\n",
    "    hasil2.append(np.mean(pred2))\n",
    "    print(\"akurasi 5-fold : \", pred2)\n",
    "\n",
    "    #classification\n",
    "    data2 = []\n",
    "    for i in y_pred:\n",
    "        data2.append(int(i))\n",
    "        \n",
    "    modus = st.mode(data2)\n",
    "    print(\"Hasil Klasifikasi : \", modus)\n",
    "print(hasil2)\n",
    "\n",
    "print(\"\\nMENGGUNAKAN MINKOWSKI DISTANCE\")\n",
    "hasil3 = []\n",
    "for i in range (3, 10, 2):\n",
    "    pred3 = []\n",
    "    print('K =', i) \n",
    "    p = 3\n",
    "    start3 = time.time()\n",
    "    model = KNN_MINKOWSKI(k=i, p=p)\n",
    "    for train_index, test_index in kf.split(X_Modeled):\n",
    "        X_train, X_test = X_Modeled[train_index], X_Modeled[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.train(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        end3 = time.time()\n",
    "        acc = accuracy(y_test, y_pred)\n",
    "        pred3.append(acc)\n",
    "        \n",
    "        print(confusion_matrix(y_test, y_pred)) \n",
    "        print(classification_report(y_test, y_pred))\n",
    "         \n",
    "    print(\"akurasi : \", np.mean(pred3))\n",
    "    hasil3.append(np.mean(pred3))\n",
    "    print(\"akurasi 5-fold : \", pred3)\n",
    "\n",
    "    #classification\n",
    "    data3 = []\n",
    "    for i in y_pred:\n",
    "        data3.append(int(i))\n",
    "        \n",
    "    modus = st.mode(data3)\n",
    "    print(\"Hasil Klasifikasi : \", modus)\n",
    "print(hasil3)\n",
    "print(f\"Runtime KNN with Euclidean Distance : {end1-start1}\")\n",
    "print(f\"Runtime KNN with Manhattan Distance : {end2-start2}\")\n",
    "print(f\"Runtime KNN with Minkowski Distance : {end3-start3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392a87d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.581854</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.037175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.057199</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.078895</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.503937</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297830</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.130112</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.508621</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>0.449541</td>\n",
       "      <td>0.092937</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>0.049310</td>\n",
       "      <td>0.367232</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098619</td>\n",
       "      <td>0.463277</td>\n",
       "      <td>0.155963</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.467890</td>\n",
       "      <td>0.197026</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.167653</td>\n",
       "      <td>0.129944</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.361582</td>\n",
       "      <td>0.486239</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1    2    3         4         5         6         7   \\\n",
       "0    0.814815  0.066667  0.0  0.0  0.693333  0.087912  0.581854  0.717514   \n",
       "1    0.407407  0.200000  0.0  0.0  0.986667  0.868132  0.057199  0.073446   \n",
       "2    0.333333  0.000000  0.0  0.0  0.986667  0.791209  0.078895  0.050847   \n",
       "3    0.481481  0.066667  0.0  0.0  0.226667  0.000000  0.297830  0.796610   \n",
       "4    0.259259  0.066667  0.0  0.0  0.213333  0.000000  0.428008  0.694915   \n",
       "..        ...       ...  ...  ...       ...       ...       ...       ...   \n",
       "420  0.500000  0.533333  0.0  0.0  0.773333  0.065934  0.049310  0.367232   \n",
       "421  0.555556  0.600000  0.0  0.0  0.880000  0.296703  0.090730  0.225989   \n",
       "422  0.555556  0.400000  0.0  0.4  0.680000  0.000000  0.098619  0.463277   \n",
       "423  0.629630  0.533333  0.0  0.0  0.893333  0.219780  0.167653  0.129944   \n",
       "424  0.629630  0.466667  0.0  0.0  0.893333  0.219780  0.120316  0.361582   \n",
       "\n",
       "           8         9         10        11        12   13  \n",
       "0    0.055046  0.551724  0.708661  0.678899  0.037175  1.0  \n",
       "1    0.587156  0.068966  0.535433  0.477064  0.000000  1.0  \n",
       "2    0.623853  0.068966  0.503937  0.440367  0.000000  0.5  \n",
       "3    0.000000  0.620690  0.574803  0.486239  0.130112  0.5  \n",
       "4    0.045872  0.508621  0.480315  0.449541  0.092937  0.5  \n",
       "..        ...       ...       ...       ...       ...  ...  \n",
       "420  0.376147  0.318966  0.574803  0.532110  0.011152  0.5  \n",
       "421  0.568807  0.284483  0.614173  0.568807  0.000000  0.5  \n",
       "422  0.155963  0.258621  0.582677  0.467890  0.197026  1.0  \n",
       "423  0.678899  0.241379  0.661417  0.623853  0.003717  1.0  \n",
       "424  0.486239  0.413793  0.732283  0.688073  0.014870  1.0  \n",
       "\n",
       "[425 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d8a062a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   250.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:26:48</td>     <th>  Log-Likelihood:    </th> <td> -988.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2126</td>      <th>  AIC:               </th> <td>   2006.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2112</td>      <th>  BIC:               </th> <td>   2085.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.8148</td> <td>    0.093</td> <td>    8.787</td> <td> 0.000</td> <td>    0.633</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   -0.3375</td> <td>    0.047</td> <td>   -7.163</td> <td> 0.000</td> <td>   -0.430</td> <td>   -0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.7657</td> <td>    0.155</td> <td>    4.946</td> <td> 0.000</td> <td>    0.462</td> <td>    1.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>    1.8521</td> <td>    0.101</td> <td>   18.250</td> <td> 0.000</td> <td>    1.653</td> <td>    2.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>    0.6552</td> <td>    0.046</td> <td>   14.332</td> <td> 0.000</td> <td>    0.566</td> <td>    0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>    1.0629</td> <td>    0.053</td> <td>   19.974</td> <td> 0.000</td> <td>    0.959</td> <td>    1.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>    0.2937</td> <td>    0.086</td> <td>    3.413</td> <td> 0.001</td> <td>    0.125</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>    2.9797</td> <td>    0.171</td> <td>   17.470</td> <td> 0.000</td> <td>    2.645</td> <td>    3.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    2.1773</td> <td>    0.108</td> <td>   20.212</td> <td> 0.000</td> <td>    1.966</td> <td>    2.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   -1.5326</td> <td>    0.159</td> <td>   -9.639</td> <td> 0.000</td> <td>   -1.844</td> <td>   -1.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   -0.5165</td> <td>    0.191</td> <td>   -2.700</td> <td> 0.007</td> <td>   -0.892</td> <td>   -0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>   -1.4921</td> <td>    0.244</td> <td>   -6.123</td> <td> 0.000</td> <td>   -1.970</td> <td>   -1.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>    0.7561</td> <td>    0.118</td> <td>    6.396</td> <td> 0.000</td> <td>    0.524</td> <td>    0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>    0.1650</td> <td>    0.046</td> <td>    3.559</td> <td> 0.000</td> <td>    0.074</td> <td>    0.256</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>244.156</td> <th>  Durbin-Watson:     </th> <td>   0.891</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 527.245</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.695</td>  <th>  Prob(JB):          </th> <td>3.24e-115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.005</td>  <th>  Cond. No.          </th> <td>    53.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.607\n",
       "Model:                            OLS   Adj. R-squared:                  0.604\n",
       "Method:                 Least Squares   F-statistic:                     250.5\n",
       "Date:                Mon, 28 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        15:26:48   Log-Likelihood:                -988.87\n",
       "No. Observations:                2126   AIC:                             2006.\n",
       "Df Residuals:                    2112   BIC:                             2085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.8148      0.093      8.787      0.000       0.633       0.997\n",
       "x2            -0.3375      0.047     -7.163      0.000      -0.430      -0.245\n",
       "x3             0.7657      0.155      4.946      0.000       0.462       1.069\n",
       "x4             1.8521      0.101     18.250      0.000       1.653       2.051\n",
       "x5             0.6552      0.046     14.332      0.000       0.566       0.745\n",
       "x6             1.0629      0.053     19.974      0.000       0.959       1.167\n",
       "x7             0.2937      0.086      3.413      0.001       0.125       0.462\n",
       "x8             2.9797      0.171     17.470      0.000       2.645       3.314\n",
       "x9             2.1773      0.108     20.212      0.000       1.966       2.389\n",
       "x10           -1.5326      0.159     -9.639      0.000      -1.844      -1.221\n",
       "x11           -0.5165      0.191     -2.700      0.007      -0.892      -0.141\n",
       "x12           -1.4921      0.244     -6.123      0.000      -1.970      -1.014\n",
       "x13            0.7561      0.118      6.396      0.000       0.524       0.988\n",
       "x14            0.1650      0.046      3.559      0.000       0.074       0.256\n",
       "==============================================================================\n",
       "Omnibus:                      244.156   Durbin-Watson:                   0.891\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              527.245\n",
       "Skew:                           0.695   Prob(JB):                    3.24e-115\n",
       "Kurtosis:                       5.005   Cond. No.                         53.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "sl = 0.05\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_Modeled).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99cefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0691db1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   162.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:26:48</td>     <th>  Log-Likelihood:    </th> <td> -986.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2126</td>      <th>  AIC:               </th> <td>   2016.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2105</td>      <th>  BIC:               </th> <td>   2135.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                             <td></td>                               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>baseline_value</th>                                         <td>    0.8344</td> <td>    0.119</td> <td>    6.995</td> <td> 0.000</td> <td>    0.600</td> <td>    1.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accelerations</th>                                          <td>    0.0026</td> <td>    0.070</td> <td>    0.037</td> <td> 0.970</td> <td>   -0.135</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fetal_movement</th>                                         <td>    0.0405</td> <td>    0.092</td> <td>    0.439</td> <td> 0.661</td> <td>   -0.140</td> <td>    0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uterine_contractions</th>                                   <td>   -0.3434</td> <td>    0.048</td> <td>   -7.096</td> <td> 0.000</td> <td>   -0.438</td> <td>   -0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>light_decelerations</th>                                    <td>   -0.0517</td> <td>    0.079</td> <td>   -0.654</td> <td> 0.513</td> <td>   -0.207</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>severe_decelerations</th>                                   <td>    0.7611</td> <td>    0.156</td> <td>    4.879</td> <td> 0.000</td> <td>    0.455</td> <td>    1.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prolongued_decelerations</th>                               <td>    1.8110</td> <td>    0.118</td> <td>   15.397</td> <td> 0.000</td> <td>    1.580</td> <td>    2.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abnormal_short_term_variability</th>                        <td>    0.6455</td> <td>    0.051</td> <td>   12.716</td> <td> 0.000</td> <td>    0.546</td> <td>    0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mean_value_of_short_term_variability</th>                   <td>    0.0113</td> <td>    0.112</td> <td>    0.102</td> <td> 0.919</td> <td>   -0.207</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percentage_of_time_with_abnormal_long_term_variability</th> <td>    1.0663</td> <td>    0.057</td> <td>   18.742</td> <td> 0.000</td> <td>    0.955</td> <td>    1.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mean_value_of_long_term_variability</th>                    <td>    0.2944</td> <td>    0.109</td> <td>    2.697</td> <td> 0.007</td> <td>    0.080</td> <td>    0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_width</th>                                        <td>    3.0747</td> <td>    0.227</td> <td>   13.554</td> <td> 0.000</td> <td>    2.630</td> <td>    3.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_min</th>                                          <td>    2.2395</td> <td>    0.134</td> <td>   16.658</td> <td> 0.000</td> <td>    1.976</td> <td>    2.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_max</th>                                          <td>   -1.5781</td> <td>    0.180</td> <td>   -8.784</td> <td> 0.000</td> <td>   -1.930</td> <td>   -1.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_number_of_peaks</th>                              <td>   -0.0527</td> <td>    0.079</td> <td>   -0.669</td> <td> 0.504</td> <td>   -0.207</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_number_of_zeroes</th>                             <td>    0.1239</td> <td>    0.129</td> <td>    0.958</td> <td> 0.338</td> <td>   -0.130</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_mode</th>                                         <td>   -0.4697</td> <td>    0.195</td> <td>   -2.405</td> <td> 0.016</td> <td>   -0.853</td> <td>   -0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_mean</th>                                         <td>   -0.3831</td> <td>    0.263</td> <td>   -1.456</td> <td> 0.146</td> <td>   -0.899</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_median</th>                                       <td>   -1.2205</td> <td>    0.328</td> <td>   -3.724</td> <td> 0.000</td> <td>   -1.863</td> <td>   -0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_variance</th>                                     <td>    0.7513</td> <td>    0.125</td> <td>    5.988</td> <td> 0.000</td> <td>    0.505</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>histogram_tendency</th>                                     <td>    0.1650</td> <td>    0.047</td> <td>    3.537</td> <td> 0.000</td> <td>    0.074</td> <td>    0.256</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>237.892</td> <th>  Durbin-Watson:     </th> <td>   0.888</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 514.911</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.679</td>  <th>  Prob(JB):          </th> <td>1.54e-112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.992</td>  <th>  Cond. No.          </th> <td>    75.4</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.607\n",
       "Model:                            OLS   Adj. R-squared:                  0.604\n",
       "Method:                 Least Squares   F-statistic:                     162.8\n",
       "Date:                Mon, 28 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        15:26:48   Log-Likelihood:                -986.93\n",
       "No. Observations:                2126   AIC:                             2016.\n",
       "Df Residuals:                    2105   BIC:                             2135.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================================\n",
       "                                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------------------------\n",
       "baseline_value                                             0.8344      0.119      6.995      0.000       0.600       1.068\n",
       "accelerations                                              0.0026      0.070      0.037      0.970      -0.135       0.140\n",
       "fetal_movement                                             0.0405      0.092      0.439      0.661      -0.140       0.221\n",
       "uterine_contractions                                      -0.3434      0.048     -7.096      0.000      -0.438      -0.248\n",
       "light_decelerations                                       -0.0517      0.079     -0.654      0.513      -0.207       0.103\n",
       "severe_decelerations                                       0.7611      0.156      4.879      0.000       0.455       1.067\n",
       "prolongued_decelerations                                   1.8110      0.118     15.397      0.000       1.580       2.042\n",
       "abnormal_short_term_variability                            0.6455      0.051     12.716      0.000       0.546       0.745\n",
       "mean_value_of_short_term_variability                       0.0113      0.112      0.102      0.919      -0.207       0.230\n",
       "percentage_of_time_with_abnormal_long_term_variability     1.0663      0.057     18.742      0.000       0.955       1.178\n",
       "mean_value_of_long_term_variability                        0.2944      0.109      2.697      0.007       0.080       0.509\n",
       "histogram_width                                            3.0747      0.227     13.554      0.000       2.630       3.520\n",
       "histogram_min                                              2.2395      0.134     16.658      0.000       1.976       2.503\n",
       "histogram_max                                             -1.5781      0.180     -8.784      0.000      -1.930      -1.226\n",
       "histogram_number_of_peaks                                 -0.0527      0.079     -0.669      0.504      -0.207       0.102\n",
       "histogram_number_of_zeroes                                 0.1239      0.129      0.958      0.338      -0.130       0.378\n",
       "histogram_mode                                            -0.4697      0.195     -2.405      0.016      -0.853      -0.087\n",
       "histogram_mean                                            -0.3831      0.263     -1.456      0.146      -0.899       0.133\n",
       "histogram_median                                          -1.2205      0.328     -3.724      0.000      -1.863      -0.578\n",
       "histogram_variance                                         0.7513      0.125      5.988      0.000       0.505       0.997\n",
       "histogram_tendency                                         0.1650      0.047      3.537      0.000       0.074       0.256\n",
       "==============================================================================\n",
       "Omnibus:                      237.892   Durbin-Watson:                   0.888\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              514.911\n",
       "Skew:                           0.679   Prob(JB):                    1.54e-112\n",
       "Kurtosis:                       4.992   Cond. No.                         75.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "sl = 0.05\n",
    "regressor_OLS = sm.OLS(endog = y, exog = dataset).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def diss(j):\n",
    "#     dis_i = []\n",
    "#     for i in range (len(X)):\n",
    "#         #print(\"i \",i)\n",
    "#         dis_i.append(KNN_EUCLIDEAN.jarak_euclidean(X[i],X[j]))\n",
    "# #     print(\"=========================\")\n",
    "#     return dis_i\n",
    "# # print(diss(2))\n",
    "# dis = []\n",
    "# for i in range (len(X)):\n",
    "#     dis.append(diss(i))\n",
    "\n",
    "# for i in range (len(dis)):\n",
    "#     arr1 = np.sort(dis[i])\n",
    "#     print(arr1[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c582f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
